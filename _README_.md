# Gesture Detection using OpenCV and SmolVLM

## ğŸ“Œ Project Overview
This project implements a **gesture detection system** using:
- **OpenCV + MediaPipe** (for hand tracking and gesture classification)
- **SmolVLM** (as an alternative detection module)

It benchmarks and compares both approaches in terms of **CPU usage, memory usage, and FPS performance**.  
The system detects hand presence, identifies hand side (Left/Right), counts fingers, and recognizes gestures like **Thumbs Up/Down**.

---

## âœ¨ Features
- âœ… **Hand Detection** â†’ Detects if a hand is present and its bounding box  
- âœ… **Hand Side Identification** â†’ Left Hand / Right Hand  
- âœ… **Finger Counting** â†’ Counts 0â€“5 open fingers  
- âœ… **Gesture Recognition**:
  - ğŸ‘ Thumbs Up
  - ğŸ‘ Thumbs Down
  - âœŠ Hand Down (Fist)
  - â˜ Index Finger
  - âœŒ Middle Finger
  - ğŸ¤Ÿ Ring Finger
  - ğŸ¤˜ Little Finger
  - ğŸ– Open Hand
- âœ… **Both Hands Detection** (simultaneously)  
- âœ… **Logging** â†’ CPU, memory usage, FPS, gesture results  
- âœ… **Benchmarking** â†’ Compare OpenCV vs SmolVLM  

---

## ğŸ“‚ Folder Structure
```
Gesture_Recognition_unzipped/
â”œâ”€â”€ Gesture_Recognition/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â”œâ”€â”€ results_summary.csv
â”‚   â”‚   â”œâ”€â”€ run_benchmarks.py
â”‚   â”œâ”€â”€ opencv/
â”‚   â”‚   â”œâ”€â”€ architecture.md
â”‚   â”‚   â”œâ”€â”€ architecture_diagram.pdf
â”‚   â”‚   â”œâ”€â”€ dfd.md
â”‚   â”‚   â”œâ”€â”€ dfd_diagram.pdf
â”‚   â”‚   â”œâ”€â”€ gesture_opencv.py
â”‚   â”‚   â”œâ”€â”€ gesture_outputs.log
â”‚   â”‚   â”œâ”€â”€ gutputs.log
â”‚   â”‚   â”œâ”€â”€ frames_open cv/
â”‚   â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”‚   â”œâ”€â”€ Left_Hand Down_20250929_182828_348.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ Left_Index Finger_20250929_182828_347.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ Left_Left 2 Fingers_20250929_190159_113.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ Left_Left Four Fingers_20250929_190751_92.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ... (many more gesture images)
â”‚   â”œâ”€â”€ smolvlm/
â”‚   â”‚   â”œâ”€â”€ architecture.md
â”‚   â”‚   â”œâ”€â”€ architecture_diagram.pdf
â”‚   â”‚   â”œâ”€â”€ dfd.md
â”‚   â”‚   â”œâ”€â”€ dfd_diagram.pdf
â”‚   â”‚   â”œâ”€â”€ gesture_smolvlm.py
â”‚   â”‚   â”œâ”€â”€ gesture_outputs.log
â”‚   â”‚   â”œâ”€â”€ frames_smolvlm/
â”‚   â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”‚   â””â”€â”€ ... (gesture frames)
```

---

## âš™ï¸ Installation

### 1. Clone the repo
```bash
git clone https://github.com/Nithinnithu0610/Gesture_detection-using-opencv-and-smolVLM-method.git
cd Gesture_detection-using-opencv-and-smolVLM-method
```

### 2. Create and activate virtual environment
```bash
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### Run OpenCV Gesture Detection
```bash
python opencv/gesture_opencv.py --out_dir opencv/frames_open\ cv --log opencv/gesture_outputs.log
```

### Run SmolVLM Gesture Detection
```bash
python smolvlm/gesture_smolvlm.py --out_dir smolvlm/frames_smolvlm --log smolvlm/gesture_outputs.log
```

### Run Benchmarks (20 seconds)
```bash
python benchmarks/run_benchmarks.py 20
```

---

## ğŸ“¤ Outputs

1. **Gesture Logs**  
   - `opencv/gesture_outputs.log`  
   - `smolvlm/gesture_outputs.log`  

2. **Saved Frames**  
   Snapshots stored in:
   - `opencv/frames_open cv/`
   - `smolvlm/frames_smolvlm/`

3. **Benchmarks Summary**  
   - `benchmarks/results_summary.csv`

---

## ğŸ“‹ Requirements
- Python 3.10+
- OpenCV
- MediaPipe
- psutil
- pillow
- numpy

Install them via:
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Notes
- Press **Q** to quit gesture detection.  
- Ensure your **camera is free** before running benchmarks.  
- Logs and frames will be saved automatically.  

---

## ğŸ‘¨â€ğŸ’» Author
**Nithin**  
GitHub: [Nithinnithu0610](https://github.com/Nithinnithu0610)
